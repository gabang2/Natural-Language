{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c29a578e",
   "metadata": {},
   "source": [
    "# 1. Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "322d0e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "292d9728",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = ['너 오늘 이뻐 보인다',\n",
    "          '나는 오늘 기분이 더러워',\n",
    "          '끝내주는데, 좋은 일이 있나봐',\n",
    "          '나 좋은 일이 생겼어',\n",
    "          '아 오늘 진짜 짜증나',\n",
    "          '환상적인데, 정말 좋은거 같아']\n",
    "targets = [[1], [0], [1], [1], [0], [1]]\n",
    "\n",
    "tokenizer = preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(samples)\n",
    "sequences = tokenizer.texts_to_sequences(samples)\n",
    "input_sequences = np.array(sequences)\n",
    "labels = np.array(targets)\n",
    "\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5132279a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "num_epochs = 100\n",
    "vocab_size = len(word_index) + 1\n",
    "emb_size=128\n",
    "hidden_dimension=256\n",
    "output_dimension=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "64fc2498",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Embedding(vocab_size, emb_size, input_length=4))\n",
    "model.add(layers.Lambda(lambda x:tf.reduce_mean(x, axis=1))) #lambda : 임베딩된 벡터를 평균하기 위함\n",
    "model.add(layers.Dense(hidden_dimension, activation=\"relu\"))\n",
    "model.add(layers.Dense(output_dimension, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d5d22a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001), loss=\"binary_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d8c52d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 2s 11ms/step - loss: 0.6910 - accuracy: 0.6667\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.6723 - accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6531 - accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6362 - accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6171 - accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5915 - accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5649 - accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5316 - accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4938 - accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4541 - accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4088 - accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3592 - accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3120 - accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2647 - accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2201 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1803 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1447 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1148 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0940 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0736 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0578 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0435 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0357 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0279 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0230 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0189 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0154 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0130 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0115 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0098 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0089 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 9.8070e-04 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 9.5171e-04 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 9.2954e-04 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 9.0544e-04 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 8.8414e-04 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 8.6097e-04 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 8.4226e-04 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 8.2061e-04 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 8.0224e-04 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 7.8078e-04 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 7.6418e-04 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 7.4630e-04 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 7.2877e-04 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 7.1393e-04 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.9686e-04 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 6.8151e-04 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 6.6655e-04 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 6.5314e-04 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 6.3724e-04 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.2482e-04 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.1359e-04 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.9931e-04 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 5.8821e-04 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 5.7614e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1eb0de89190>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(input_sequences, labels, epochs=num_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dbdb65",
   "metadata": {},
   "source": [
    "# 2. 사이킷런"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c99ca8",
   "metadata": {},
   "source": [
    "##### (1) iris 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5aaa33fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최근접 이웃 accuracy : 1.0\n",
      "[2 1 1 1 2 1 1 1 1 1 2 1 1 1 2 2 2 1 1 1 1 1 2 1 1 1 1 2 1 1 1 2 1 1 1 1 1\n",
      " 1 1 1 1 1 1 2 2 1 2 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 1 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "'''1. 데이터 불러오기'''\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "iris_dataset=load_iris()\n",
    "# print(iris_dataset.keys(),iris_dataset)\n",
    "train_input, test_input, train_label, test_label = train_test_split(iris_dataset['data'],\n",
    "                                                                    iris_dataset['target'], test_size=0.25, random_state=42)\n",
    "\n",
    "'''2. K-Neighbors Classifier'''\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(train_input, train_label)\n",
    "print(\"최근접 이웃 accuracy : {}\".format(np.mean(knn.predict(test_input)==test_label)))\n",
    "\n",
    "'''3. 비지도 학습'''\n",
    "from sklearn.cluster import KMeans\n",
    "k_means = KMeans(n_clusters=3)\n",
    "k_means.fit(train_input)\n",
    "print(train_label[k_means.labels_==0])\n",
    "print(train_label[k_means.labels_==1])\n",
    "print(train_label[k_means.labels_==2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b5480f",
   "metadata": {},
   "source": [
    "##### (2) 단어 특징 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cba3f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'나는': 3, '배가': 7, '고프다': 0, '내일': 4, '점심': 8, '뭐먹지': 6, '공부해야겠다': 1, '먹고': 5, '공부해야지': 2}\n",
      "[[1 0 0 1 0 0 0 1 0]]\n",
      "{'나는': 3, '배가': 7, '고프다': 0, '내일': 4, '점심': 8, '뭐먹지': 6, '공부해야겠디': 1, '먹고': 5, '공부해야지': 2}\n",
      "[[0.         0.         0.61761437 0.         0.         0.61761437\n",
      "  0.         0.         0.48693426]]\n"
     ]
    }
   ],
   "source": [
    "'''1. CountVectorizer'''\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "text_data = ['나는 배가 고프다', '내일 점심 뭐먹지', '내일 공부해야겠다.', '점심 먹고 공부해야지']\n",
    "count_vectorizer = CountVectorizer()\n",
    "count_vectorizer.fit(text_data)\n",
    "sentence = [text_data[0]]\n",
    "print(count_vectorizer.vocabulary_)\n",
    "print(count_vectorizer.transform(sentence).toarray())\n",
    "\n",
    "'''2. TfidVectorizer'''\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "text_data = ['나는 배가 고프다', '내일 점심 뭐먹지', '내일 공부해야겠디', '점심 먹고 공부해야지']\n",
    "tfidf_vectorizer= TfidfVectorizer()\n",
    "tfidf_vectorizer.fit(text_data)\n",
    "print(tfidf_vectorizer.vocabulary_)\n",
    "sentence = ['점심 먹고 공부해야지']\n",
    "print(tfidf_vectorizer.transform(sentence).toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f91049",
   "metadata": {},
   "source": [
    "# 3. 자연어 토크나이징 도구"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec2e292",
   "metadata": {},
   "source": [
    "#### (1) 영어 토크나이징 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a95ae69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안할거임'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''안할거임'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee410c75",
   "metadata": {},
   "source": [
    "#### (2) 한글 토크나이징 라이브러리 - KoNLPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b68499ee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['한글', '자연어', '처리', '는', '재밌다', '이제', '부터', '열심히', '해야지', 'ㅎㅎㅎ']\n",
      "['한글', '자연어', '처리', '는', '재밌다', '이제', '부터', '열심히', '하다', 'ㅎㅎㅎ']\n",
      "['한글', '자연어', '처리', '이제']\n",
      "['한글', '한글 자연어', '한글 자연어 처리', '이제', '자연어', '처리']\n",
      "[('한글', 'Noun'), ('자연어', 'Noun'), ('처리', 'Noun'), ('는', 'Josa'), ('재밌다', 'Adjective'), ('이제', 'Noun'), ('부터', 'Josa'), ('열심히', 'Adverb'), ('해야지', 'Verb'), ('ㅎㅎㅎ', 'KoreanParticle')]\n",
      "['한글/Noun', '자연어/Noun', '처리/Noun', '는/Josa', '재밌다/Adjective', '이제/Noun', '부터/Josa', '열심히/Adverb', '해야지/Verb', 'ㅎㅎㅎ/KoreanParticle']\n",
      "대한민국헌법\n",
      "\n",
      "유구한 역사와 전통에 \n",
      "지방공무원법 일부개\n"
     ]
    }
   ],
   "source": [
    "'''1. konlpy의 메서드 사용하기'''\n",
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "text = \"한글 자연어 처리는 재밌다 이제부터 열심히 해야지ㅎㅎㅎ\"\n",
    "print(okt.morphs(text))\n",
    "print(okt.morphs(text, stem=True))\n",
    "print(okt.nouns(text))\n",
    "print(okt.phrases(text))\n",
    "print(okt.pos(text))\n",
    "print(okt.pos(text, join=True))\n",
    "\n",
    "'''2. konlpy 내장 데이터 사용하기'''\n",
    "from konlpy.corpus import kolaw\n",
    "from konlpy.corpus import kobill\n",
    "print(kolaw.open('constitution.txt').read()[:20])\n",
    "print(kobill.open('1809890.txt').read()[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0779fc93",
   "metadata": {},
   "source": [
    "#### (2) re 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12597730",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "re.compile(' \\\\W+')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'number candy'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "pattern =\" \\W+\"\n",
    "re_pattern = re.compile(pattern)\n",
    "print(re_pattern)\n",
    "re_name = re.search(\"(\\w+)\", \"wow, it is awesome\")\n",
    "re.split('\\W', 'wow, it is world of word')\n",
    "re.sub('\\d', 'number', '7 candy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bb2c59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33212faa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0599811",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
